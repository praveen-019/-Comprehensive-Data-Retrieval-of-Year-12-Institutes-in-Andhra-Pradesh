{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CSV file path\n",
    "csv_file = \"colleges.csv\"\n",
    "\n",
    "def retrieveInfoFromCollege(url):\n",
    "    # Sending a GET request to the URL, ignoring SSL verification\n",
    "    response = requests.get(url, verify=False)\n",
    "\n",
    "    # Checking if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Finding the table containing the required information\n",
    "        table = soup.find('table', class_='table-bordered')\n",
    "\n",
    "        if table:\n",
    "            # Extracting data from table rows\n",
    "            rows = table.find_all('tr')\n",
    "            college_info = {}\n",
    "            for row in rows:\n",
    "                ths = row.find_all('th')\n",
    "                tds = row.find_all('td')\n",
    "                if len(ths) == len(tds):  # Ensure equal number of th and td pairs\n",
    "                    for th, td in zip(ths, tds):\n",
    "                        college_info[th.text.strip()] = td.text.strip()\n",
    "\n",
    "            # Writing the extracted information into csv\n",
    "            with open(csv_file, 'a', newline='') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=[\"College Name\", \"College Address\", \"Principal Phone No\", \"College STD & Land Phone\"])\n",
    "                \n",
    "                # Write the data\n",
    "                writer.writerow({\n",
    "                    \"College Name\": college_info.get('College Name', 'Not found'),\n",
    "                    \"College Address\": ''.join([line.rstrip('\\n') for line in college_info.get('College Address', 'Not found')]),\n",
    "                    \"Principal Phone No\": college_info.get('Principal Phone No', 'Not found'),\n",
    "                    \"College STD & Land Phone\": college_info.get('College STD & Land Phone', 'Not found')\n",
    "                })\n",
    "                \n",
    "        else:\n",
    "            print(\"Table not found on the webpage.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve data from the webpage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b596bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveCollegeFromMandal(url):\n",
    "    # Sending a GET request to the URL, ignoring SSL verification\n",
    "    response = requests.get(url, verify=False)\n",
    "\n",
    "    # Checking if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Finding the table containing the required information\n",
    "        table = soup.find('table', class_='table-bordered')\n",
    "\n",
    "        if table:\n",
    "            # Extracting data from table rows\n",
    "            tbody = table.find('tbody')\n",
    "            if tbody:\n",
    "                rows = tbody.find_all('tr')\n",
    "                college_links = []\n",
    "                for row in rows:\n",
    "                    # Extracting link associated with the college name\n",
    "                    college_name_cell = row.find_all('td')[5]  # 5th cell contains college name\n",
    "                    link = college_name_cell.find('a')\n",
    "                    if link:\n",
    "                        onclick_attr = link.get('onclick')\n",
    "                        # Extracting the URL from onclick attribute\n",
    "                        url_match = re.search(r\"'(.*?)'\", onclick_attr)\n",
    "                        if url_match:\n",
    "                            college_url = url_match.group(1)\n",
    "                            full_url = f\"https://bieap.apcfss.in/{college_url}\"\n",
    "                            college_links.append(full_url)\n",
    "\n",
    "                # calling retireveInfoFromCollege function on the list of formatted URLs\n",
    "                for link in college_links:\n",
    "                    retrieveInfoFromCollege(link)\n",
    "        else:\n",
    "            print(\"Table not found on the webpage.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve data from the webpage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e00a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveMandalFromDistrict(url):\n",
    "    # Sending a GET request to the URL, ignoring SSL verification\n",
    "    response = requests.get(url, verify=False)\n",
    "\n",
    "    # Checking if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Finding the table containing the required information\n",
    "        table = soup.find('table', class_='table-bordered')\n",
    "\n",
    "        if table:\n",
    "            # Extracting data from table rows\n",
    "            tbody = table.find('tbody')\n",
    "            if tbody:\n",
    "                rows = tbody.find_all('tr')\n",
    "                mandal_links = []\n",
    "                for row in rows:\n",
    "                    # Extracting the onclick link from the \"Total Colleges\" column (third cell)\n",
    "                    total_colleges_cell = row.find_all('td')[2]  # 3rd cell contains total colleges\n",
    "                    link = total_colleges_cell.find('a')\n",
    "                    if link:\n",
    "                        onclick_attr = link.get('onclick')\n",
    "                        onclick_attr = onclick_attr.replace('¶m', '&param')\n",
    "                        # Extracting the URL from onclick attribute\n",
    "                        url_match = re.search(r\"'(.*?)'\", onclick_attr)\n",
    "                        if url_match:\n",
    "                            onclick_link = url_match.group(1)\n",
    "                            full_link = f\"https://bieap.apcfss.in/{onclick_link}\"\n",
    "                            mandal_links.append(full_link)\n",
    "\n",
    "                # calling retrieveCollegeFromMandal function on the list of formatted URLs\n",
    "                for link in mandal_links:\n",
    "                    retrieveCollegeFromMandal(link)\n",
    "        else:\n",
    "            print(\"Table not found on the webpage.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve data from the webpage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5404e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the webpage\n",
    "url = \"https://bieap.apcfss.in/CollegesReport.do\"\n",
    "\n",
    "# Sending a GET request to the URL, ignoring SSL verification\n",
    "response = requests.get(url, verify=False)\n",
    "\n",
    "# Checking if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parsing the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Finding the table containing the required information\n",
    "    table = soup.find('table', class_='table-bordered')\n",
    "    \n",
    "    if table:\n",
    "        # Extracting data from table rows\n",
    "        tbody = table.find('tbody')\n",
    "        if tbody:\n",
    "            rows = tbody.find_all('tr')\n",
    "            district_links = []\n",
    "            for row in rows:\n",
    "                # Extracting the onclick link associated with the district name (second cell)\n",
    "                district_name_cell = row.find_all('td')[1]  # 2nd cell contains district name\n",
    "                link = district_name_cell.find('a')\n",
    "                if link:\n",
    "                    onclick_attr = link.get('onclick')\n",
    "                    onclick_attr = onclick_attr.replace('¶m', '&param')\n",
    "                    # Extracting the URL from onclick attribute\n",
    "                    url_match = re.search(r\"'(.*?)'\", onclick_attr)\n",
    "                    if url_match:\n",
    "                        onclick_link = url_match.group(1)\n",
    "                        full_link = f\"https://bieap.apcfss.in/{onclick_link}\"\n",
    "                        district_links.append(full_link)\n",
    "            # calling retrieveCollegeFromMandal function on the list of formatted URLs\n",
    "            for link in district_links:\n",
    "                retrieveMandalFromDistrict(link)\n",
    "    else:\n",
    "        print(\"Table not found on the webpage.\")\n",
    "else:\n",
    "    print(\"Failed to retrieve data from the webpage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a548af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
